{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Autism_ConvMixer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOH5whPKTSe5bQl5RTxzXmk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sutummala/AutismNet/blob/main/Autism_ConvMixer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIteo4LrhHsr",
        "outputId": "899094f0-3b51-48ac-f75b-8d70bd3755e0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBTSxj0qHMjT",
        "outputId": "efd4f81d-558c-4e0d-dddc-28614bc4c6c0"
      },
      "source": [
        "!pip install tensorflow_addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN5Vyh5SeK7k"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2xmK07thMAx"
      },
      "source": [
        "def normalize(input):\n",
        "  norm_input = []\n",
        "  print(f'shape of input is {np.shape(input[0])}')\n",
        "  for i in range(np.shape(input)[0]):\n",
        "    norm_in = (input[i]-np.min(input[i]))/(np.max(input[i])-np.min(input[i]))\n",
        "    norm_input.append(norm_in)\n",
        "  return np.array(norm_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBDoEHV2hlNU",
        "outputId": "a5606a99-9340-4f13-a387-d67d61831a4c"
      },
      "source": [
        "healthy_data = np.load('/content/drive/My Drive/Datasets/Autism/healthy_patches.npy')\n",
        "healthy_data = normalize(healthy_data)\n",
        "#healthy_data_2 = np.load('/content/drive/My Drive/Datasets/Autism/healthy_patches_2.npy')\n",
        "#healthy_data = np.concatenate((healthy_data_1, healthy_data_2))\n",
        "healthy_labels = np.zeros(np.shape(healthy_data)[0])\n",
        "\n",
        "autism_data = np.load('/content/drive/My Drive/Datasets/Autism/autism_patches.npy')\n",
        "autism_data = normalize(autism_data)\n",
        "#autism_data_2 = np.load('/content/drive/My Drive/Datasets/Autism/autism_patches_2.npy')\n",
        "#autism_data = np.concatenate((autism_data_1, autism_data_2))\n",
        "autism_labels = np.ones(np.shape(autism_data)[0])\n",
        "\n",
        "index = int(0.9 * healthy_data.shape[0])\n",
        "\n",
        "X = np.concatenate((healthy_data[:index], autism_data[:index])) \n",
        "X_train = np.expand_dims(X, axis = -1)\n",
        "healthy_test = np.expand_dims(healthy_data[index:], axis = -1) \n",
        "autism_test = np.expand_dims(autism_data[index:], axis = -1)\n",
        "\n",
        "y_train = np.concatenate((healthy_labels[:index], autism_labels[:index]))\n",
        "healthy_test_labels = healthy_labels[index:]\n",
        "autism_test_labels = autism_labels[index:]\n",
        "\n",
        "X_test = np.concatenate((healthy_test, autism_test))\n",
        "y_test = np.concatenate((healthy_test_labels, autism_test_labels))\n",
        "\n",
        "print(f'no.of healthy patches for testing are {np.shape(healthy_test_labels)[0]}')\n",
        "print(f'no.of diseased patches for testing are {np.shape(autism_test_labels)[0]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of input is (32, 32, 32)\n",
            "shape of input is (32, 32, 32)\n",
            "no.of healthy patches for testing are 368\n",
            "no.of diseased patches for testing are 728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vi235qhh1Kl",
        "outputId": "c196bd5d-b04f-4cb3-fe45-5f6a741f4ad2"
      },
      "source": [
        "folds = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 1)\n",
        "\n",
        "#X_train = np.expand_dims(X_train, axis = -1) * 255 # expanding dimensions\n",
        "\n",
        "for train_index, test_index in folds.split(X_train, y_train):\n",
        "    input_cv, input_test, targets_cv, targets_test = X_train[train_index], X_train[test_index], y_train[train_index], y_train[test_index]\n",
        "\n",
        "print(f'shape of input for CV is {input_cv.shape}')\n",
        "print(f'input size for cross-validation is {len(targets_cv)}')\n",
        "print(f'no.of healthy in CV are {np.shape(np.nonzero(targets_cv))[1]}')\n",
        "\n",
        "#left_input_test = left_input[cv_index:]\n",
        "#right_input_test = right_input[cv_index:]\n",
        "#targets_test = targets[cv_index:]\n",
        "\n",
        "print(f'shape of input for testing is {input_test.shape}')\n",
        "print(f'input size for testing is {len(targets_test)}')\n",
        "print(f'no.of healthy in test are {np.shape(np.nonzero(targets_test))[1]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of input for CV is (5287, 32, 32, 32, 1)\n",
            "input size for cross-validation is 5287\n",
            "no.of healthy in CV are 2643\n",
            "shape of input for testing is (1321, 32, 32, 32, 1)\n",
            "input size for testing is 1321\n",
            "no.of healthy in test are 661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67MfiTgPeWhR"
      },
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "\n",
        "batch_size = 128\n",
        "num_epochs = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iXu9TuudInW"
      },
      "source": [
        "def activation_block(x):\n",
        "    x = layers.Activation(\"gelu\")(x)\n",
        "    return layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "def conv_stem(x, filters: int, patch_size: int):\n",
        "    x = layers.Conv3D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
        "    return activation_block(x)\n",
        "\n",
        "\n",
        "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
        "    # Depthwise convolution.\n",
        "    x0 = x\n",
        "    x = layers.Conv3D(1, kernel_size=kernel_size, padding=\"same\")(x)\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "    # Pointwise convolution.\n",
        "    x = layers.Conv3D(filters, kernel_size=1)(x)\n",
        "    x = activation_block(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_conv_mixer_256_8(\n",
        "    image_size=32, filters=256, depth=16, kernel_size=5, patch_size=4, num_classes=1\n",
        "):\n",
        "    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
        "    The hyperparameter values are taken from the paper.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input((image_size, image_size, image_size, 1))\n",
        "    #x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "    x = inputs\n",
        "    # Extract patch embeddings.\n",
        "    x = conv_stem(x, filters, patch_size)\n",
        "\n",
        "    # ConvMixer blocks.\n",
        "    for _ in range(depth):\n",
        "        x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "    # Classification block.\n",
        "    x = layers.GlobalAvgPool3D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRYlSaCGfHiw"
      },
      "source": [
        "def run_experiment(model):\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        input_cv, targets_cv,\n",
        "        validation_data=(input_test, targets_test),\n",
        "        epochs=num_epochs,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqgAPbhcfIs7",
        "outputId": "752e641b-f6fa-4609-caf9-71d2ad1aa64a"
      },
      "source": [
        "conv_mixer_model = get_conv_mixer_256_8()\n",
        "conv_mixer_model.summary()\n",
        "history, conv_mixer_model = run_experiment(conv_mixer_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 32,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv3d (Conv3D)                 (None, 16, 16, 16, 2 2304        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 16, 16, 16, 2 0           conv3d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 16, 16, 16, 2 1024        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 16, 16, 16, 2 8192256     batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 16, 16, 16, 2 0           conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 16, 16, 16, 2 1024        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 16, 16, 16, 2 0           batch_normalization_1[0][0]      \n",
            "                                                                 batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2 (Conv3D)               (None, 16, 16, 16, 2 65792       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 16, 16, 16, 2 0           conv3d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 16, 16, 16, 2 1024        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_3 (Conv3D)               (None, 16, 16, 16, 2 8192256     batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 16, 16, 16, 2 0           conv3d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 16, 16, 16, 2 1024        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 16, 16, 16, 2 0           batch_normalization_3[0][0]      \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_4 (Conv3D)               (None, 16, 16, 16, 2 65792       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 16, 2 0           conv3d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 16, 16, 16, 2 1024        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling3d (Globa (None, 256)          0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            257         global_average_pooling3d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 16,523,777\n",
            "Trainable params: 16,521,217\n",
            "Non-trainable params: 2,560\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            " 53/166 [========>.....................] - ETA: 6:23:04 - loss: 0.7349 - accuracy: 0.5259"
          ]
        }
      ]
    }
  ]
}