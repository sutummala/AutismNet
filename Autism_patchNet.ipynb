{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Autism_patchNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMugWWkGNPoeZulLHRQM6CK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sutummala/AutismNet/blob/main/Autism_patchNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nBIznotaRBs",
        "outputId": "5b07b7b1-b2f0-4c21-eb59-88eede44bd1f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OMzXu_IaXTr"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "#import tensorflow_addons as tfa\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
        "import sklearn\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "#from pytorch_grad_cam import GradCAM"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6gWYWB3g--B"
      },
      "source": [
        "healthy_data = np.load('/content/drive/My Drive/Datasets/Autism/healthy_patches_2.npy')\n",
        "#healthy_data_2 = np.load('/content/drive/My Drive/Datasets/Autism/healthy_patches_2.npy')\n",
        "#healthy_data = np.concatenate((healthy_data_1, healthy_data_2))\n",
        "healthy_labels = np.zeros(np.shape(healthy_data)[0])\n",
        "\n",
        "autism_data = np.load('/content/drive/My Drive/Datasets/Autism/autism_patches_2.npy')\n",
        "#autism_data_2 = np.load('/content/drive/My Drive/Datasets/Autism/autism_patches_2.npy')\n",
        "#autism_data = np.concatenate((autism_data_1, autism_data_2))\n",
        "autism_labels = np.ones(np.shape(autism_data)[0])\n",
        "\n",
        "index = int(0.8 * healthy_data.shape[0])\n",
        "\n",
        "X = np.concatenate((healthy_data[:index], autism_data[:index])) * 255\n",
        "X_train = np.expand_dims(X, axis = -1)\n",
        "healthy_test = np.expand_dims(healthy_data[index:], axis = -1) \n",
        "autism_test = np.expand_dims(autism_data[index:], axis = -1)\n",
        "\n",
        "y_train = np.concatenate((healthy_labels[:index], autism_labels[:index]))\n",
        "healthy_test_labels = healthy_labels[index:]\n",
        "autism_test_labels = autism_labels[index:]\n",
        "\n",
        "X_test = np.concatenate((healthy_test, autism_test))\n",
        "y_test = np.concatenate((healthy_test_labels, autism_test_labels))\n",
        "\n",
        "print(f'no.of healthy patches for testing are {np.shape(healthy_test_labels)[0]}')\n",
        "print(f'no.of diseased patches for testing are {np.shape(autism_test_labels)[0]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J91dWXtWlhlb"
      },
      "source": [
        "print(f'no.of healthy patches for testing are {np.shape(X_test)[0]}')\n",
        "print(f'no.of diseased patches for testing are {np.shape(y_test)[0]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POR4Jqo5bhew"
      },
      "source": [
        "folds = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 1)\n",
        "\n",
        "#X_train = np.expand_dims(X_train, axis = -1) * 255 # expanding dimensions\n",
        "\n",
        "for train_index, test_index in folds.split(X_train, y_train):\n",
        "    input_cv, input_test, targets_cv, targets_test = X_train[train_index], X_train[test_index], y_train[train_index], y_train[test_index]\n",
        "\n",
        "print(f'shape of input for CV is {input_cv.shape}')\n",
        "print(f'input size for cross-validation is {len(targets_cv)}')\n",
        "print(f'no.of healthy in CV are {np.shape(np.nonzero(targets_cv))[1]}')\n",
        "\n",
        "#left_input_test = left_input[cv_index:]\n",
        "#right_input_test = right_input[cv_index:]\n",
        "#targets_test = targets[cv_index:]\n",
        "\n",
        "print(f'shape of input for testing is {input_test.shape}')\n",
        "print(f'input size for testing is {len(targets_test)}')\n",
        "print(f'no.of healthy in test are {np.shape(np.nonzero(targets_test))[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i70uzI0fgLG"
      },
      "source": [
        "img_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3], 1, )\n",
        "print(img_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0lnHb69eE2j"
      },
      "source": [
        "model = tf.keras.Sequential(name = 'patchNet')\n",
        "\n",
        "model.add(tf.keras.layers.Conv3D(8, (3, 3, 3), input_shape = img_shape, strides = (1,1,1), padding = 'same', kernel_regularizer = 'L2', name = 'conv3d_1'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.SpatialDropout3D(0.1))\n",
        "\n",
        "model.add(tf.keras.layers.Conv3D(16, (3, 3, 3), strides = (1,1,1), padding = 'same', kernel_regularizer = 'L2', name = 'conv3d_2'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling3D(strides = (2, 2, 2)))\n",
        "model.add(tf.keras.layers.SpatialDropout3D(0.1))\n",
        "\n",
        "model.add(tf.keras.layers.Conv3D(32, (3, 3, 3), strides = (1,1,1), padding = 'same', kernel_regularizer = 'L2', name = 'conv3d_3'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling3D(strides = (2, 2, 2)))\n",
        "model.add(tf.keras.layers.SpatialDropout3D(0.1))\n",
        "\n",
        "model.add(tf.keras.layers.Conv3D(64, (3, 3, 3), strides = (1,1,1), padding = 'same', kernel_regularizer = 'L2', name = 'conv3d_4'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling3D(strides = (2, 2, 2)))\n",
        "#model.add(tf.keras.layers.SpatialDropout3D(0.1))\n",
        "\n",
        "model.add(tf.keras.layers.Conv3D(128, (3, 3, 3), strides = (1,1,1), padding = 'same', kernel_regularizer = 'L2', name = 'conv3d_5'))\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling3D(strides = (2, 2, 2)))\n",
        "#model.add(tf.keras.layers.SpatialDropout3D(0.1))\n",
        "\n",
        "model.add(tf.keras.layers.GlobalAveragePooling3D())\n",
        "model.add(tf.keras.layers.Dense(256, kernel_regularizer = 'L2', activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(256, kernel_regularizer = 'L2', activation = 'relu'))\n",
        "#model.add(tf.keras.layers.GaussianNoise(0.1))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(256, kernel_regularizer = 'L2', activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "#patchNet_model = tf.keras.Model(inputs = input, outputs =  output, name = 'patchNet')\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXRD-4L_jFgc"
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate = 0.0005), loss = 'binary_crossentropy', metrics = 'accuracy')\n",
        "    \n",
        "no_of_epochs = 200\n",
        "\n",
        "history_fine = model.fit(input_cv, targets_cv, batch_size = 32,\n",
        "                              epochs = no_of_epochs,\n",
        "                              shuffle = True\n",
        "                              validation_data = (input_test, targets_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ-kVViEjl8Q"
      },
      "source": [
        "predicton_prob = model.predict(X_test)\n",
        "\n",
        "print(np.transpose(predicton_prob))\n",
        "\n",
        "predicton_prob[predicton_prob > 0.5] = 1\n",
        "predicton_prob[predicton_prob <= 0.5] = 0\n",
        "\n",
        "tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y_test, predicton_prob).ravel()\n",
        "\n",
        "targets_test = y_test\n",
        "\n",
        "print(f'test Accuracy: {sklearn.metrics.accuracy_score(targets_test, predicton_prob)}')\n",
        "print(f'test ROC (AUC): {sklearn.metrics.roc_auc_score(targets_test, predicton_prob)}')\n",
        "print(f'test Sensitivity (Recall): {sklearn.metrics.recall_score(targets_test, predicton_prob)}')\n",
        "print(f'test Precision: {sklearn.metrics.precision_score(targets_test, predicton_prob)}')\n",
        "print(f'test F1-score: {sklearn.metrics.f1_score(targets_test, predicton_prob)}')\n",
        "print(f'test Mathews Correlation Coefficient: {sklearn.metrics.matthews_corrcoef(targets_test, predicton_prob)}')\n",
        "print(f'test Specificity: {tn/(tn+fp)}')\n",
        "print(targets_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}